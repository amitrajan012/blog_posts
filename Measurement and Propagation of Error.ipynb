{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "div.text_cell_render { /* Customize text cells */\n",
       "font-family: 'Times New Roman';\n",
       "font-size:1.3em;\n",
       "line-height:1.4em;\n",
       "padding-left:1.5em;\n",
       "padding-right:1.5em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    "div.text_cell_render { /* Customize text cells */\n",
    "font-family: 'Times New Roman';\n",
    "font-size:1.3em;\n",
    "line-height:1.4em;\n",
    "padding-left:1.5em;\n",
    "padding-right:1.5em;\n",
    "}\n",
    "</style>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Measurement and Propagation of Error</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any measurement in a scientific or an engineering process, consists of two error parts: <b>systematic error</b> or <b>bias</b> and <b>random error</b>. The bias is the part of the error that is same for every measurement. Random error varies from measurement to measurement and averages out to 0 in the long run. Hence, the measured value can be written as:\n",
    "\n",
    "$$Measured \\ Value = True \\ Value + Bias + Random \\ Error$$\n",
    "\n",
    "The <b>mean</b> $\\mu$ of the population represents the part of the measurement that is the same for every measurement. Hence, $\\mu$ is the <b>sum of the true value and the bias</b>. The smaller the bias, the more accurate the measuring process is. If the mean is equal to the true value, the measuring process is said to be <b>unbiased</b>. The <b>standard deviation</b> $\\sigma$ of the population is the the standard deviation of the random error. The <b>precision</b> of the measurement is determined by the standard deviation of the measurement process. The smaller the value of $\\sigma$, the more precise the process. $\\sigma$ is often referred to as the <b>uncertainty</b> in the measuring process.\n",
    "\n",
    "For example, if $X_1, X_2, ..., X_n$ are the independent measurements, all made on the same quantity by the same process, the <b>sample standard deviation</b> $s$ can be used to estimate the <b>uncertainty</b> in the process. If the <b>true value</b> of the measuring quantity is known, the sample mean $\\overline{X}$ can be used to estimate the bias as $Bias \\approx \\overline{X} - True \\ Value$. If the true value is unknown, the bias can not be estimated from the repeated measurements. If bias has been reduced to a negligible level, the measurements can be described as:\n",
    "\n",
    "$$Measured \\ Value \\pm \\sigma$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Combinations of Independent Measurements :\n",
    "\n",
    "If $X$ is a measurement and $c$ a constant, then the <b>uncertainty</b> in the measurement of $cX$ can be given as:\n",
    "\n",
    "$$\\sigma_{cX} = \\left|c\\right| \\sigma_{X}$$\n",
    "\n",
    "For the independet measurements $X_1,X_2, ..., X_n$ and constants $c_1, c_2, ..., c_n$, the <b>uncertainty</b> of the measurement $c_1X_1 + c_2X_2 + ... + c_nX_n$ is given as:\n",
    "\n",
    "$$\\sigma_{c_1X_1 + c_2X_2 + ... + c_nX_n} = \\sqrt{c_1^2\\sigma_{X_1}^2 + c_2^2\\sigma_{X_2}^2 + ... + c_n^2\\sigma_{X_n}^2}$$\n",
    "\n",
    "The above mentioned calculation of uncertainties is a simple implication of the linear combination of random variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repeated Measurements :\n",
    "\n",
    "Taking repeated independent measurements of the same quantity is a good way to reduce the overall uncertainty or variance of the measurement. The average of these measuerements will have the same mean but the standard deviation will be reduced by a factor of square root of number of measurements. Hence, for $n$ <b>independent measurements</b> $X_1,X_2, ..., X_n$, each with mean $\\mu$ and uncertainty $\\sigma$, the sample mean $\\overline{X}$ is a measurement with mean\n",
    "\n",
    "$$\\mu_{\\overline{X}} = \\mu$$\n",
    "\n",
    "and with uncertainty\n",
    "\n",
    "$$\\sigma_{\\overline{X}} = \\frac{\\sigma}{\\sqrt{n}}$$\n",
    "\n",
    "For the case of the repeated measurements $X_1,X_2, ..., X_n$ with different uncertainties $\\sigma_{X_1}, \\sigma_{X_2}, ..., \\sigma_{X_n}$, the ovearall uncertainty of the <b>average measurement</b> can be given as:\n",
    "\n",
    "$$\\sigma_{avg} = \\sqrt{\\frac{1}{n^2}\\sigma_{X_1}^2 + \\frac{1}{n^2}\\sigma_{X_2}^2 + ... + \\frac{1}{n^2}\\sigma_{X_n}^2}$$\n",
    "\n",
    "Instead, we can also take the <b>weighted average</b> by taking fractions $c_1, c_2, ..., c_n$ measurements each individual one such that $c_1 + c_2 + ... + c_n = 1$. The uncertainty of the final weighted average measurement will be:\n",
    "\n",
    "$$\\sigma_{weighted \\ average} = \\sqrt{c_1^2\\sigma_{X_1}^2 + c_2^2\\sigma_{X_2}^2 + ... + c_n^2\\sigma_{X_n}^2}$$\n",
    "\n",
    "<b>Example: </b> An engineer measures the period of a pendulum (in seconds) to be 2.0 ± 0.2 s. Another independent measurement is made with a more precise clock, and the result is 2.2 ± 0.1 s. The average of these two measurements is 2.1 s. Find the uncertainty in this quantity.\n",
    "\n",
    "<b>Sol: </b> The uncertainty will be:\n",
    "\n",
    "$$\\sigma_{avg} = \\sqrt{\\frac{1}{n^2}\\sigma_{X}^2 + \\frac{1}{n^2}\\sigma_{Y}^2} = \\sqrt{\\frac{1}{4}(0.2)^2 + \\frac{1}{4}(0.1)^2} = 0.11s$$\n",
    "\n",
    "<b>Example: </b> In the above scenario, another engineer suggests that since Y is a more precise measurement than X, a weighted average in which Y is weighted more heavily than X might be more precise than the unweighted average. Express the uncertainty in the weighted average $cX + (1 − c)Y$ in terms of $c$, and find the value of c that minimizes the uncertainty\n",
    "\n",
    "<b>Sol: </b> The uncertainty for the weighted average is given as:\n",
    "\n",
    "$$\\sigma_{weighted \\ average} = \\sqrt{c^2\\sigma_{X}^2 + (1-c)^2\\sigma_{Y}^2} = \\sqrt{0.04c^2 + 0.01(1-c)^2} = \\sqrt{0.05c^2 - 0.02c + 0.01}$$\n",
    "\n",
    "Taking derivative with respect to $c$ and computing it to 0, we get\n",
    "\n",
    "$$\\frac{d\\sigma_{weighted \\ average}}{dc} = 0.10c - 0.02 = 0$$\n",
    "\n",
    "and hence, the required value of $c$ is <b>0.2</b>. The new mean and uncertainty is\n",
    "\n",
    "$$\\mu_{weighted \\ average} = 0.2X + 0.8Y = 2.16$$\n",
    "\n",
    "$$\\sigma_{weighted \\ average} = \\sqrt{0.04(0.2)^2 + 0.01(0.8)^2} = 0.09s$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Combinations of Dependent Measurements :\n",
    "\n",
    "In the case of dependent measurement, to quantify the uncertainty, we need to know the value of <b>covariance</b> for all the possible pairs of measurements. This is practically not feasible. In this case, an upper bound can be placed on the uncertainty. If $X_1, X_2, ..., X_n$ are $n$ dependent measurements and $c_1, c_2, ..., c_n$ are constants, then the uncertainty of $c_1X_1 + c_2X_2 + ... + c_nX_n$ can be bounded as:\n",
    "\n",
    "$$\\sigma_{c_1X_1 + c_2X_2 + ... + c_nX_n} \\leq |c_1|\\sigma_{X_1} + |c_2|\\sigma_{X_2} + ... + |c_n|\\sigma_{X_n}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uncertainties for Functions of One Measurement :\n",
    "\n",
    "If $X$ is a measurement whose uncertainty $\\sigma_X$ is <b>small</b> and if $U$ is a funaction of $X$, then uncertainty in the measurement of $U$ can be approximated as (where the derivative is computed at the observed measurement $X$):\n",
    "\n",
    "$$\\sigma_U \\approx \\bigg| \\frac{dU}{dX} \\bigg| \\sigma_X$$\n",
    "\n",
    "The above approximation can be proved by using a simple mathematical technique. A <b>Taylor Series</b> of a function $f(X)$, which is <b>infinitely differentiable</b> at $a$ is given as:\n",
    "\n",
    "$$f(a) + \\frac{f^{'}(a)}{1!}(x-a) + \\frac{f^{''}(a)}{2!}(x-a)^2 + \\frac{f^{'''}(a)}{3!}(x-a)^3 + ...$$\n",
    "\n",
    "In our case, if $X$ is close to $\\mu_X$, then the <b>first-order Taylor Serirs approximation</b> for $U(X)$ can be given as:\n",
    "\n",
    "$$U(X) \\approx U(\\mu_X) + \\frac{U^{'}(\\mu_X)}{1!}(x-\\mu_X) = U(\\mu_X) + \\frac{dU}{dX}(X-\\mu_X)$$\n",
    "\n",
    "where $\\frac{dU}{dX}$ is evaluated at $\\mu_X$. It should be noted that for any reasonable precise measurement, $X$ will be close enough to $\\mu_{X}$ for the Taylor series approximation to be valid. Rearranging the above expression, we get\n",
    "\n",
    "$$U(X) \\approx  \\bigg( U(\\mu_X) - \\frac{dU}{dX} \\mu_{X} \\bigg) + \\frac{dU}{dX}X$$\n",
    "\n",
    "As $\\frac{dU}{dX}$ is measured at $\\mu_X$, it is constant and hence the quantity inside the bracket is constant. This gives the uncertainty (<b>standard deviation</b>) as:\n",
    "\n",
    "$$\\sigma_U \\approx \\bigg| \\frac{dU}{dX} \\bigg| \\sigma_X$$\n",
    "\n",
    "This is the <b>propagation of error</b> formula and is applied in almost all the back-propagation algorithms in <b>neural-networks</b> as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uncertainties for Functions of Several Measurements :\n",
    "\n",
    "If $X_1, X_2, ..., X_n$ are <b>independent measurements</b> whose uncertainties $\\sigma_{X_1}, \\sigma_{X_2}, ..., \\sigma_{X_n}$ are <b>small</b> and if $U = U(X_1, X_2, ..., X_n)$ is a function of $X_1, X_2, ..., X_n$, then\n",
    "\n",
    "$$\\sigma_U \\approx \\sqrt{\\bigg( \\frac{\\partial U}{\\partial X_1}\\bigg)^2 \\sigma_{X_1}^2 + \\bigg( \\frac{\\partial U}{\\partial X_2}\\bigg)^2 \\sigma_{X_2}^2 + ... + \\bigg( \\frac{\\partial U}{\\partial X_n}\\bigg)^2 \\sigma_{X_n}^2}$$\n",
    "\n",
    "This is the <b>multivariate propagation of error formula</b> and is valid only when the measurements are independent. This formula can be derived in a similar way as the one discussed for the one measurement case.\n",
    "\n",
    "<b>Example: </b>Two resistors with resistances R1 and R2 are connected in parallel. The combined resistance R is given by R = (R1R2)/(R1+ R2). If R1 is measured to be 100±10, and R2 is measured to be 20±1, estimate R and find the uncertainty in the estimate.\n",
    "\n",
    "<b>Sol:</b> The estimate of $R$ can be given as $\\frac{100 \\times 20}{100 + 20}$ = <b>16.67</b>. First of all, we need to compute the partial derivative of R as:\n",
    "\n",
    "$$\\frac{\\partial R}{\\partial R1} = \\bigg( \\frac{R2}{R1+R2}\\bigg)^2 = 0.0278$$\n",
    "\n",
    "$$\\frac{\\partial R}{\\partial R2} = \\bigg( \\frac{R1}{R1+R2}\\bigg)^2 = 0.694$$\n",
    "\n",
    "Now, $\\sigma_{R1} = 10$ and $\\sigma_{R2} = 1$, and hence\n",
    "\n",
    "$$\\sigma_{R} = \\sqrt{\\bigg( \\frac{\\partial R}{\\partial R1}\\bigg)^2 \\sigma_{R1}^2 + \\bigg( \\frac{\\partial R}{\\partial R2}\\bigg)^2 \\sigma_{R2}^2} = 0.75$$\n",
    "\n",
    "Hence, the combined resistance is <b>16.67 ± 0.75</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uncertainties for Functions of Dependent Measurements :\n",
    "\n",
    "In the case of the <b>dependent</b> measurements, the uncertainty can be calculated accurately if the covariance of each pair of measurements is known. Instead, we can give a conservative estimate for uncertainty as (where the terms have usual meaning):\n",
    "\n",
    "$$\\sigma_{U} \\leq \\bigg| \\frac{\\partial U}{\\partial X_1}\\bigg| \\sigma_{X_1} + \\bigg| \\frac{\\partial U}{\\partial X_2}\\bigg| \\sigma_{X_2} + ... + \\bigg| \\frac{\\partial U}{\\partial X_n}\\bigg| \\sigma_{X_n}$$\n",
    "\n",
    "This inequality is valid for almost all the cases of dependent measurements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reference:\n",
    "\n",
    "https://www.mheducation.com/highered/product/statistics-engineers-scientists-navidi/M0073401331.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
